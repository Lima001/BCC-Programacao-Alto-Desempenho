{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introdução ao CuPy: Continuação**\n",
        "Esse documento serve como uma continuação à discussão iniciada na [Aula sobre Programação em GPU com CuPy](https://docs.google.com/document/d/19IQpXYaSxXlUSM9tGaO_LjyKNaq3c3bNYxiKSRTaSw0/edit?usp=sharing) (abre em nova guia). Antes de iniciar a apresentação do tema, cabe destacar algumas observações:\n",
        "\n",
        "- O Colab (versão gratuita) permite a alocação de um único ambiente de execução virtual simultâneo. Cada ambiente pode alocar uma máquina com uma CPU, ou uma GPU;\n",
        "\n",
        "  **A execução dos exemplos que utilizam o CuPy necessitam da alocação de uma máquina com GPU como acelerador de hardware. Sendo assim, recomenda-se alterar o ambiente de execução, que por padrão usa a CPU como acelerador, para utilizar a GPU.**\n",
        "\n",
        "  Obs. A configuração necessária pode ser efetuada seguindo os menus \"Ambiente de execução\" > \"Alterar o tipo de ambiente de execução\" e marcar a opção de GPU para \"Acelerador de hardware\".\n",
        "\n",
        "- O Colab já suporta a biblioteca CuPy, logo, sua instalação não é discutida. Caso seja necessário configurar uma máquina fora da plataforma, recomenda-se a leitura de [18];\n",
        "\n",
        "- O assunto é discutido na forma de exemplos práticos. Cada um possui trechos de código Python e seus respectivos resultados de execução;\n",
        "\n",
        "- Para facilitar, cada exemplo é propositalmente encapsulado com todos os comandos necessários para sua execução. Assim, não é preciso sequencialmente executar os trechos de código apresentados;\n",
        "\n",
        "- Caso os exemplos sejam re-executados, é possível que resultados ligeiramente sejam obtidos; não é possível garantir a alocação de máquinas com o mesmo estado da utilizada para elaboração do material. Além disso, existem os aspectos da latência de rede e a carga das máquinas virtuais em núvem que devem ser observados.\n"
      ],
      "metadata": {
        "id": "PevImy_Kyt2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 00: Ambiente de execução\n",
        "\n",
        "Antes de iniciar a apresentação de exemplos usando CuPy é interessante destacar as configurações do ambiente de execução atual, como Informações de hardware e a versão da linguagem Python (e das bibliotecas utilizadas)."
      ],
      "metadata": {
        "id": "mYfGecjR9KiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir a versão do Python\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tTlzDmC9q3F",
        "outputId": "4374a2a5-d752-4ee9-8321-bf7afffcd484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as versões das bibliotecas NumPy e CuPy\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "print(f\"Versão do NumPy: {np.__version__}\")\n",
        "print(f\"Versão do CuPy: {cp.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ntDgvgB9xYi",
        "outputId": "c3f901ba-ca7e-4c1e-85d0-9aeda676971d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão do NumPy: 1.23.5\n",
            "Versão do CuPy: 11.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caso o trecho de código anterior apresentar algum erro relacionado ao CuPy, é importante **certificar que a GPU foi devidamente escolhida como acelerador de hardware** (conforme mencionado no texto introdutório)."
      ],
      "metadata": {
        "id": "5MURmiLK_mfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir informações sobre a GPU disponível\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjwUcIy8AJI7",
        "outputId": "5aa0e480-096c-46f1-d8df-2c5ce8a3c2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 23 22:40:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como resultados da execução anterior são obtidas informações como o modelo da GPU, seus drivers, versão do CUDA e dados sobre possíveis processamentos."
      ],
      "metadata": {
        "id": "TyM7ZKzwSTVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01: Arrays NumPy e CuPy\n",
        "Esse exemplo tem como objetivo apresentar a estrutura de dados básica da biblioteca CuPy. Para comparação, a mesma apresentação é feita com a biblioteca NumPy."
      ],
      "metadata": {
        "id": "jBS3dlOR7tPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "# Criando arrays NumPy - processados pela CPU - a partir de uma lista Python\n",
        "x_cpu = np.array([1, 2, 3, 4, 5])\n",
        "y_cpu = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Criando arrays CuPy - Processados pela GPU - a partir de uma lista Python\n",
        "x_gpu = cp.array([1, 2, 3, 4, 5])\n",
        "y_gpu = cp.array([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "0R-d8H8Z8GMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, percebe-se que ambos os casos possuem uma definição similar. A diferença está no fato de que ao criar um array em CuPy, os dados são alocados na GPU [19].\n",
        "\n",
        "O NumPy e o CuPy implementam diversas funcionalidades para operar sobre o objeto array. As implementações em CuPy seguem um subconjunto do API do NumPy, isto é, alguns métodos e funções vistas em NumPy são também observadas em CuPy. A API completa do CuPy está disponível em [20] e os próximos exemplos exploram algumas de suas operações.\n",
        "\n",
        "Finalizando o exemplo, ao executar o comando para obter informações da GPU novamente, destaca-se o incremento na memória utilizada; explicitando que os arrays CuPy foram transferidos para a placa de vídeo."
      ],
      "metadata": {
        "id": "l8pU31n2Tkfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEpmIbyPUQPl",
        "outputId": "3102a299-dd72-4380-9464-608a185c71d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 23 22:40:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    26W /  70W |    131MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 02: Operações básicas em CuPy\n",
        "O objetivo desse exemplo é apresentar algumas operações simples que podem ser executadas com a estrutura de dados do CuPy."
      ],
      "metadata": {
        "id": "RFXhBWYPWsXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Criando arrays para exemplo\n",
        "x = cp.array([1, 3, 5, 7, 9])\n",
        "y = cp.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Operações aritméticas simples\n",
        "print(f\"x+10: {x+10}\")\n",
        "print(f\"10*x: {10*x}\")\n",
        "print(f\"x+y: {x+y}\")\n",
        "print(f\"x-y: {x-y}\")\n",
        "print(f\"x*y: {x*y}\")\n",
        "print(f\"x/y: {x/y}\")\n",
        "\n",
        "# Acesso indexado de itens\n",
        "print(f\"Acessando x[1]: {x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb_X-0FqXCMM",
        "outputId": "ac571d5f-1d69-4fb5-e04c-4ca4d624bd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operações aritméticas simples\n",
            "[11 13 15 17 19]\n",
            "[10 30 50 70 90]\n",
            "[ 3  7 11 15 19]\n",
            "[-1 -1 -1 -1 -1]\n",
            "[ 2 12 30 56 90]\n",
            "[0.5        0.75       0.83333333 0.875      0.9       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os arrays em CuPy são similares ao NumPy; ambos implementam uma estrurua similar aos vetores da matemática. Além de dados arrays unidimensionais, é possível criar estruturas de dados n-dimensionais."
      ],
      "metadata": {
        "id": "Ij-mhmZPY6Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando arrays multidimensionais\n",
        "x = cp.array([[0,1,2,3],[3,2,1,0]])\n",
        "y = cp.array([[0,1,2,3],[3,2,1,0]])\n",
        "\n",
        "# Exemplo de operação nos dados criados\n",
        "print(\"x+y:\", x+y, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B02aJbLUZuvc",
        "outputId": "3d9534f8-67cc-4cbd-97c7-453ed9f41c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x+y:\n",
            "[[0 2 4 6]\n",
            " [6 4 2 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 03: Métodos e funções CuPy\n",
        "Esse exemplo apresenta alguns métodos e funções auxiliares úteis para o desenvolvimento de programas numéricos. Em sequência são destacadas operações para criação de dados."
      ],
      "metadata": {
        "id": "eH5x6UwQaZwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando array multidimensional preenchido por zeros (dados ponto flutuantes).\n",
        "# Assinatura do método: cupy.zeros(shape, dtype=<class 'float'>, order='C').\n",
        "matriz_nula = cp.zeros((3,3))\n",
        "print(\"Matriz nula: \", matriz_nula, sep=\"\\n\")\n",
        "\n",
        "# Criando array multidimensional preenchido por uns (dados ponto flutuantes).\n",
        "# Assinatura do método: cupy.zeros(shape, dtype=<class 'float'>, order='C').\n",
        "matriz_um = cp.ones((3,3))\n",
        "print(\"Matriz de uns: \", matriz_um, sep=\"\\n\")\n",
        "\n",
        "# Criando matriz identidade de ordem n\n",
        "# Assinatura do método:  cupy.identity(n, dtype=<class 'float'>).\n",
        "identidade = cp.identity(3)\n",
        "print(\"Matriz identidade: \", identidade, sep=\"\\n\")\n",
        "\n",
        "# Criando vetor em intervalo de dados [start,stop]\n",
        "# Assinatura do método:  cupy.arange(start, stop=None, step=1, dtype=None)\n",
        "vetor = cp.arange(0,10,dtype=float)\n",
        "print(\"Vetor: \", vetor, sep=\"\\n\")\n",
        "print()\n",
        "\n",
        "# Exemplos de funções matemáticas\n",
        "print(f\"cos(vetor):\\n {cp.cos(vetor)}\")\n",
        "print(f\"sin(vetor[0]):\\n {cp.sin(vetor[0])}\")\n",
        "print(f\"sqrt(vetor):\\n {cp.sqrt(vetor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8AxIg8HarL9",
        "outputId": "736d4a40-3fbd-4173-afb8-2ac7b5a0ab07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz nula: \n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "Matriz de uns: \n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "Matriz identidade: \n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Vetor: \n",
            "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
            "\n",
            "cos(vetor):\n",
            " [ 1.          0.54030231 -0.41614684 -0.9899925  -0.65364362  0.28366219\n",
            "  0.96017029  0.75390225 -0.14550003 -0.91113026]\n",
            "sin(vetor[0]):\n",
            " 0.0\n",
            "sqrt(vetor):\n",
            " [0.         1.         1.41421356 1.73205081 2.         2.23606798\n",
            " 2.44948974 2.64575131 2.82842712 3.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 04: Multiplicação de Matrizes\n",
        "Como o NumPy é uma biblioteca focada para computação científica e numérica, diversos métodos prontos de operações em matrizes já são nativamente implementados. O CuPy por seguir a API do NumPy traz os mesmos recursos. Em sequência apresenta-se um exemplo de multiplicação entre duas matrizes."
      ],
      "metadata": {
        "id": "DBGfWsGacl8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Configurando um gerador de números aleatórios (na verdade, pseudo-aleatórios...)\n",
        "prng = cp.random.RandomState(1234567890)\n",
        "\n",
        "# Criando matrizes 3x3 com valores aleatórios (inteiros)\n",
        "matrizA = prng.randint(0, 10, (3,3))\n",
        "matrizB = prng.randint(0, 10, (3,3))\n",
        "\n",
        "print(\"Matriz A: \", matrizA, sep=\"\\n\", end=\"\\n\\n\")\n",
        "print(\"Matriz B: \", matrizB, sep=\"\\n\", end=\"\\n\\n\")\n",
        "print()\n",
        "\n",
        "# Criando matrizes 3x3 com valores aleatórios (float de 64 bits)\n",
        "matrizC = prng.rand(3,3,dtype=cp.float64)\n",
        "matrizD = prng.rand(3,3,dtype=cp.float64)\n",
        "\n",
        "print(\"Matriz C: \", matrizC, sep=\"\\n\", end=\"\\n\\n\")\n",
        "print(\"Matriz D: \", matrizD, sep=\"\\n\", end=\"\\n\\n\")\n",
        "print()\n",
        "\n",
        "# Criando uma matriz identidade (dados inteiros)\n",
        "matrizI_int = cp.identity(3, dtype=int)\n",
        "\n",
        "# Criando uma matriz identidade (dados float de 64 bits)\n",
        "matrizI_float = cp.identity(3, dtype=cp.float64)\n",
        "\n",
        "# Realizando a multiplicação de matrizes (função dot())\n",
        "print(\"A*I: \", cp.dot(matrizA, matrizI_int), sep=\"\\n\", end=\"\\n\\n\")\n",
        "print(\"A*B: \", cp.dot(matrizA, matrizB), sep=\"\\n\", end=\"\\n\\n\")\n",
        "print()\n",
        "print(\"C*I: \", cp.dot(matrizA, matrizI_float), sep=\"\\n\", end=\"\\n\\n\")\n",
        "print(\"C*D: \", cp.dot(matrizC, matrizD), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_02elLREfx3_",
        "outputId": "cdfd5ace-0a00-4caf-915a-13ed27cc9fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz A: \n",
            "[[7 0 9]\n",
            " [9 0 9]\n",
            " [0 8 5]]\n",
            "\n",
            "Matriz B: \n",
            "[[7 3 5]\n",
            " [1 4 4]\n",
            " [7 8 1]]\n",
            "\n",
            "\n",
            "Matriz C: \n",
            "[[0.75813701 0.75667375 0.19768611]\n",
            " [0.31704807 0.70806868 0.40827932]\n",
            " [0.49842092 0.94124336 0.31793853]]\n",
            "\n",
            "Matriz D: \n",
            "[[0.52774489 0.74223001 0.51045686]\n",
            " [0.36427102 0.14882728 0.16334185]\n",
            " [0.8686915  0.76484707 0.2901141 ]]\n",
            "\n",
            "\n",
            "A*I: \n",
            "[[7 0 9]\n",
            " [9 0 9]\n",
            " [0 8 5]]\n",
            "\n",
            "A*B: \n",
            "[[112  93  44]\n",
            " [126  99  54]\n",
            " [ 43  72  37]]\n",
            "\n",
            "\n",
            "C*I: \n",
            "[[7. 0. 9.]\n",
            " [9. 0. 9.]\n",
            " [0. 8. 5.]]\n",
            "\n",
            "C*D: \n",
            "[[0.84746549 0.82652538 0.56794425]\n",
            " [0.77991818 0.65297378 0.3959442 ]\n",
            " [0.88209727 0.75320001 0.50040526]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 05: Transferência/Conversão de dados entre CPU e GPU\n",
        "Podem existir problemas ou ocasiões em que seja interessante a computação heterogênea; programação em CPU e GPU (ou outras arquiteturas) simultâneamente. Para isso, é necessário ser capaz de transferir e converter os dados entre os dispositivos. No caso do NumPy e do CuPy existem funções prontas para isso."
      ],
      "metadata": {
        "id": "h91PJWCukxjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "# Criando array NumPy - Processado pela CPU\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Criando array CuPy - Processado pela GPU\n",
        "y = cp.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Convertendo (implicitamente realizando uma operação de transferência entre os dispositivos) da CPU para GPU\n",
        "x_gpu = cp.asarray(x)\n",
        "\n",
        "# A operação contrária não é tão direta. É necessário explicitamente requerer uma cópia do dado na GPU (método get())\n",
        "y_cpu = np.asarray(y.get())"
      ],
      "metadata": {
        "id": "b8FKiIoSlSNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concluindo\n",
        "Os exemplos apresentados são um breve panorama da biblioteca CuPy. Existem diversos tópicos interessantes (e necessários) para extrair o potêncial de programação da GPU; alguns desses conceitos são:\n",
        "\n",
        "- *Current Devices:* É possível realizar a programação multi-GPU (várias GPU's) de uma vez. Com CuPy é possível gerenciar e programar os dispositivos para que atuem conjuntamente. Infelizmente, não é possível explorar o tema no Google Colab (gratuito), pois a plataforma oferece uma única GPU para o ambiente de execução;\n",
        "\n",
        "- *Current Stream:* Relembrando, um gargalo crucial do processamento em GPUs são as operações transferência de dados entre o dispositivo e a memória principal. Para evitar demasiadas operações de transferências e otimizar o uso de GPU's o CuPy oferece funcionalidades para manipulação de *streams* (canais/fluxos) de comunicação;\n",
        "\n",
        "- *Gerenciamento de Memória:* Além de otimizar o processo de transferência de dados, é importante gerenciar a memória do dispositvo. Para esse propósito são oferecidas funcionalidades de gerenciamento de memória; Limitação de memória, alocação e desalocação de blocos, *Pool* de Memória etc. são conceitos explorados pelo CuPy.\n",
        "\n",
        "Antecipando o próximo tópico do material principal, os conceitos supramencionados são inicialmente discutidos em [19] e são deixados como sugestões de leituras.\n",
        "\n",
        "Existem outros temas para exploração, porém eles são mais complexos. O CuPy permite a programação dos *user-defined kernels* para o CUDA; códigos escritos pelo programador na linguagem especifica do CUDA para programação customizada da GPU. A compreensão desse tema necessita o aprofundamento na arquitetura do CUDA e placas de vídeo modernas, algo que não é escopo do material.\n"
      ],
      "metadata": {
        "id": "mK1GMHk8oXxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gabarito Exercício 4.\n",
        "Em sequência são apresentados os códigos para o exercício 6., especificado no documento principal. É interessante evitar olhar os códigos sem antes realizar a leitura completa do material.\n",
        "\n",
        "Obs. É possível ocultar as células de código pressionando a seta no canto esquerdo da célula de texto."
      ],
      "metadata": {
        "id": "J-Jol2LoJ5CY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, antes do experimento é apresentada a informação que comprova que a biblioteca NumPy disponível foi compilada com BLAS (ou uma especificação similar). Na execução abaixo, percebe-se que foi utilizada uma implementação livre; o OpenBLAS."
      ],
      "metadata": {
        "id": "g0JOkoCWS0Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.__config__.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qsz7vdrNeit",
        "outputId": "b952c124-cc5e-4d4e-e6b8-3d1aefbcbb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openblas64__info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "blas_ilp64_opt_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "openblas64__lapack_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "lapack_ilp64_opt_info:\n",
            "    libraries = ['openblas64_', 'openblas64_']\n",
            "    library_dirs = ['/usr/local/lib']\n",
            "    language = c\n",
            "    define_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]\n",
            "    runtime_library_dirs = ['/usr/local/lib']\n",
            "Supported SIMD extensions in this NumPy install:\n",
            "    baseline = SSE,SSE2,SSE3\n",
            "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2\n",
            "    not found = AVX512F,AVX512CD,AVX512_KNL,AVX512_KNM,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "### Resultados com CPU\n",
        "# Inicializando um gerenciador de núemros pseudo-aleatórios\n",
        "prng_cpu = np.random.RandomState(0)\n",
        "\n",
        "# Criando matrizes de ordem 128 com valores aleatórios\n",
        "mA = prng_cpu.rand(128,128)\n",
        "mB = prng_cpu.rand(128,128)\n",
        "\n",
        "# Criando matrizes de ordem 1024 com valores aleatórios\n",
        "mC = prng_cpu.rand(1024,1024)\n",
        "mD = prng_cpu.rand(1024,1024)\n",
        "\n",
        "# Criando matrizes de ordem 8192 com valores aleatórios\n",
        "mE = prng_cpu.rand(8192,8192)\n",
        "mF = prng_cpu.rand(8192,8192)\n",
        "\n",
        "# Executando as multiplicações e mensurando o tempo de execução\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mA,mB)\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mC,mD)\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mE,mF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207d907f-9869-4f9c-ed69-77a2756a951c",
        "id": "QiMuYutSrzL5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
            "66.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
            "33.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "### Resultados com GPU\n",
        "\n",
        "# Copiando matrizes de ordem 100 com valores aleatórios\n",
        "mAg = cp.asarray(mA)\n",
        "mBg = cp.asarray(mB)\n",
        "\n",
        "# Copiando matrizes de ordem 1000 com valores aleatórios\n",
        "mCg = cp.asarray(mC)\n",
        "mDg = cp.asarray(mD)\n",
        "\n",
        "# Copiando matrizes de ordem 10000 com valores aleatórios\n",
        "mEg = cp.asarray(mE)\n",
        "mFg = cp.asarray(mF)\n",
        "\n",
        "# Executando as multiplicações e mensurando o tempo de execução\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mAg,mBg)\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mCg,mDg)\n",
        "%timeit -n 10 -r 1 resultado_gpu_100 = np.dot(mEg,mFg)"
      ],
      "metadata": {
        "id": "LGaiYEzqX7qU",
        "outputId": "d0cf5a3d-b656-4fc9-afdc-54be55fef14a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49.2 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
            "103 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n",
            "179 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente é perceptível que conforme maior a matriz, maior é o tempo de usuário necessário pela operação de multiplicação (em ambos os casos). Todavia, o que surpreende é a diferença de tempo entre CPU e GPU. Em todos os casos a GPU foi mais eficiente.\n",
        "\n",
        "Outro aspecto notável é a diferença de incremento no tempo entre matrizes de diferentes ordens. A CPU que iníciou com tempo de microsegundos, necessitou de 33 segundos para a matriz de maior ordem. Já a GPU manteve uma ordem de grandeza de microssegundos para todos os casos.\n",
        "\n",
        "Uma justificativa para essa observação é o foco no paralelismo de dados da GPU em relação ao paralelismo de instrução da CPU. Portanto, o hardware gráfico consegue distribuir com uma maior facilidade o processamento de mesmas instruções (operação de multiplicação) para uma grande quantidade de dados.\n",
        "\n",
        "Por fim, é importante também notar que os resultados são dependentes das características dos hardwares. Em sequência são apresentadas informações sobre a CPU e a GPU utilizadas. Uma CPU melhor possivelmente resultará em melhores resultados, todavia, ainda assim, a GPU teria uma vantagem, pois o problema de multiplicação de matriz é melhor explorado pela arquitetura desse hardware.\n",
        "\n"
      ],
      "metadata": {
        "id": "nCI9EZBVsxev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k61ljNDatG5y",
        "outputId": "e156e1e5-2ad7-448d-9375-e9bbc50110ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:          6\n",
            "    Model:               79\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            0\n",
            "    BogoMIPS:            4399.99\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n",
            "                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n",
            "                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n",
            "                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n",
            "                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n",
            "                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsa\n",
            "                         veopt arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    256 KiB (1 instance)\n",
            "  L3:                    55 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n",
            "                         gs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q"
      ],
      "metadata": {
        "id": "Tv9QTt3vuseO",
        "outputId": "fbcb6173-ca9d-4c34-f72d-b3069b464ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Thu Nov 30 13:21:16 2023\n",
            "Driver Version                            : 525.105.17\n",
            "CUDA Version                              : 12.0\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Product Name                          : Tesla T4\n",
            "    Product Brand                         : NVIDIA\n",
            "    Product Architecture                  : Turing\n",
            "    Display Mode                          : Enabled\n",
            "    Display Active                        : Disabled\n",
            "    Persistence Mode                      : Disabled\n",
            "    MIG Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Accounting Mode                       : Disabled\n",
            "    Accounting Mode Buffer Size           : 4000\n",
            "    Driver Model\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Serial Number                         : 0324218085922\n",
            "    GPU UUID                              : GPU-39fd9385-bb47-6b0b-0a8a-39c06651dd25\n",
            "    Minor Number                          : 0\n",
            "    VBIOS Version                         : 90.04.A7.00.01\n",
            "    MultiGPU Board                        : No\n",
            "    Board ID                              : 0x4\n",
            "    Board Part Number                     : 900-2G183-6300-000\n",
            "    GPU Part Number                       : 1EB8-895-A1\n",
            "    Module ID                             : 1\n",
            "    Inforom Version\n",
            "        Image Version                     : G183.0200.00.02\n",
            "        OEM Object                        : 1.1\n",
            "        ECC Object                        : 5.0\n",
            "        Power Management Object           : N/A\n",
            "    GPU Operation Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    GSP Firmware Version                  : N/A\n",
            "    GPU Virtualization Mode\n",
            "        Virtualization Mode               : Pass-Through\n",
            "        Host VGPU Mode                    : N/A\n",
            "    IBMNPU\n",
            "        Relaxed Ordering Mode             : N/A\n",
            "    PCI\n",
            "        Bus                               : 0x00\n",
            "        Device                            : 0x04\n",
            "        Domain                            : 0x0000\n",
            "        Device Id                         : 0x1EB810DE\n",
            "        Bus Id                            : 00000000:00:04.0\n",
            "        Sub System Id                     : 0x12A210DE\n",
            "        GPU Link Info\n",
            "            PCIe Generation\n",
            "                Max                       : 3\n",
            "                Current                   : 1\n",
            "                Device Current            : 1\n",
            "                Device Max                : 3\n",
            "                Host Max                  : N/A\n",
            "            Link Width\n",
            "                Max                       : 16x\n",
            "                Current                   : 16x\n",
            "        Bridge Chip\n",
            "            Type                          : N/A\n",
            "            Firmware                      : N/A\n",
            "        Replays Since Reset               : 0\n",
            "        Replay Number Rollovers           : 0\n",
            "        Tx Throughput                     : 0 KB/s\n",
            "        Rx Throughput                     : 0 KB/s\n",
            "        Atomic Caps Inbound               : N/A\n",
            "        Atomic Caps Outbound              : N/A\n",
            "    Fan Speed                             : N/A\n",
            "    Performance State                     : P8\n",
            "    Clocks Throttle Reasons\n",
            "        Idle                              : Active\n",
            "        Applications Clocks Setting       : Not Active\n",
            "        SW Power Cap                      : Not Active\n",
            "        HW Slowdown                       : Not Active\n",
            "            HW Thermal Slowdown           : Not Active\n",
            "            HW Power Brake Slowdown       : Not Active\n",
            "        Sync Boost                        : Not Active\n",
            "        SW Thermal Slowdown               : Not Active\n",
            "        Display Clock Setting             : Not Active\n",
            "    FB Memory Usage\n",
            "        Total                             : 15360 MiB\n",
            "        Reserved                          : 258 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 15101 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 256 MiB\n",
            "        Used                              : 2 MiB\n",
            "        Free                              : 254 MiB\n",
            "    Compute Mode                          : Default\n",
            "    Utilization\n",
            "        Gpu                               : 0 %\n",
            "        Memory                            : 0 %\n",
            "        Encoder                           : 0 %\n",
            "        Decoder                           : 0 %\n",
            "    Encoder Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    FBC Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    Ecc Mode\n",
            "        Current                           : Enabled\n",
            "        Pending                           : Enabled\n",
            "    ECC Errors\n",
            "        Volatile\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "        Aggregate\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 1\n",
            "            DRAM Uncorrectable            : 0\n",
            "    Retired Pages\n",
            "        Single Bit ECC                    : 0\n",
            "        Double Bit ECC                    : 0\n",
            "        Pending Page Blacklist            : No\n",
            "    Remapped Rows                         : N/A\n",
            "    Temperature\n",
            "        GPU Current Temp                  : 43 C\n",
            "        GPU T.Limit Temp                  : N/A\n",
            "        GPU Shutdown Temp                 : 96 C\n",
            "        GPU Slowdown Temp                 : 93 C\n",
            "        GPU Max Operating Temp            : 85 C\n",
            "        GPU Target Temperature            : N/A\n",
            "        Memory Current Temp               : N/A\n",
            "        Memory Max Operating Temp         : N/A\n",
            "    Power Readings\n",
            "        Power Management                  : Supported\n",
            "        Power Draw                        : 10.04 W\n",
            "        Power Limit                       : 70.00 W\n",
            "        Default Power Limit               : 70.00 W\n",
            "        Enforced Power Limit              : 70.00 W\n",
            "        Min Power Limit                   : 60.00 W\n",
            "        Max Power Limit                   : 70.00 W\n",
            "    Clocks\n",
            "        Graphics                          : 300 MHz\n",
            "        SM                                : 300 MHz\n",
            "        Memory                            : 405 MHz\n",
            "        Video                             : 540 MHz\n",
            "    Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Default Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Deferred Clocks\n",
            "        Memory                            : N/A\n",
            "    Max Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "        SM                                : 1590 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "        Video                             : 1470 MHz\n",
            "    Max Customer Boost Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "    Clock Policy\n",
            "        Auto Boost                        : N/A\n",
            "        Auto Boost Default                : N/A\n",
            "    Voltage\n",
            "        Graphics                          : N/A\n",
            "    Fabric\n",
            "        State                             : N/A\n",
            "        Status                            : N/A\n",
            "    Processes                             : None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gabarito Exercício 5.\n",
        "Código adaptado de [24]."
      ],
      "metadata": {
        "id": "4dwzXZA2eclu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Definição do kernel\n",
        "custom_kernel = cp.ElementwiseKernel(\n",
        "   'float32 x, float32 y',\n",
        "   'float32 z',\n",
        "   'z = (x*y)*(x*y)*(x*y)',\n",
        "   'custom_kernel'\n",
        ")\n",
        "\n",
        "prng = cp.random.RandomState(1234567890)\n",
        "\n",
        "v1 = prng.rand(1024,1,dtype=cp.float32)\n",
        "v2 = prng.rand(1024,1,dtype=cp.float32)\n",
        "\n",
        "v3 = custom_kernel(v1,v2)\n",
        "\n",
        "print(v1[:5], v2[:5], v3[:5], sep=\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HSZGKwu2gD6U",
        "outputId": "2c86e92a-b0bc-4fe7-ade3-addd72653886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.78493947]\n",
            " [0.7804313 ]\n",
            " [0.5672438 ]\n",
            " [0.55162865]\n",
            " [0.8867529 ]]\n",
            "[[0.15247466]\n",
            " [0.34331006]\n",
            " [0.05578661]\n",
            " [0.48251626]\n",
            " [0.5565992 ]]\n",
            "[[1.71435799e-03]\n",
            " [1.92337353e-02]\n",
            " [3.16883197e-05]\n",
            " [1.88571587e-02]\n",
            " [1.20236285e-01]]\n"
          ]
        }
      ]
    }
  ]
}